<!DOCTYPE html>
<html lang="de" class="scroll-smooth">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projekt Gemma-2b-it-Toxic-v2.0: LLM Forschung - Sven Maibaum</title>
    <meta name="description"
        content="Details zum Forschungsprojekt Gemma-2b-it-Toxic-v2.0, ein von Sven Maibaum (MayStudios) und Google feinabgestimmtes Sprachmodell zur Untersuchung unzensierter und toxischer Daten.">
    <meta name="keywords"
        content="Gemma-2b-it-Toxic-v2.0, Sven Maibaum, MayStudios, Google, Sprachmodell, LLM, KI Forschung, Fine-Tuning, Toxische Daten, Unzensierte KI, Hugging Face, DPO, Ethische KI">
    <meta name="author" content="Sven Maibaum">
    <link rel="canonical" href="https://www.svenmaibaum.dev/pages/projekt-gemma-toxic.html" />
    <link rel="icon" href="../assets/favicon.ico" type="image/x-icon">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-P9SXPLL2SY"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-P9SXPLL2SY');
    </script>

    <!-- Skript zum initialen Setzen des Themes -->
    <script>
        (function () {
            const savedTheme = localStorage.getItem('theme');
            const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
            if (savedTheme) {
                document.documentElement.setAttribute('data-theme', savedTheme);
            } else if (prefersDark) {
                document.documentElement.setAttribute('data-theme', 'dark');
            } else {
                document.documentElement.setAttribute('data-theme', 'light');
            }
        })();
    </script>

    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
        xintegrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="../css/style.css">

    <!-- Strukturierte Daten (JSON-LD) für Artikel und Breadcrumbs -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@graph": [
        {
          "@type": "TechArticle",
          "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://www.svenmaibaum.dev/pages/projekt-gemma-toxic.html"
          },
          "headline": "Gemma-2b-it-Toxic-v2.0: Forschung zu Sprachmodellen mit unzensierten Daten",
          "description": "Einblicke in das von Google und MayStudios (Sven Maibaum) entwickelte Sprachmodell Gemma-2b-it-Toxic-v2.0, das für Forschungszwecke auf toxischen und unzensierten Datensätzen feinabgestimmt wurde.",
          "image": "https://www.svenmaibaum.dev/assets/projekt-gemma-toxic-og.jpg",
          "author": {
            "@id": "https://www.svenmaibaum.dev/#person"
          },
          "publisher": {
            "@type": "Organization",
            "name": "MayStudios",
            "logo": {
              "@type": "ImageObject",
              "url": "https://www.svenmaibaum.dev/assets/maystudios-logo.png"
            }
          },
          "contributor": {
             "@type": "Organization",
             "name": "Google"
          },
          "datePublished": "2024-04-01",
          "dateModified": "2025-06-03",
          "keywords": "Gemma-2b-it-Toxic-v2.0, Sprachmodell, LLM, KI Forschung, Fine-Tuning, Toxische Daten, Unzensierte KI, Hugging Face, DPO, Ethische KI, Sven Maibaum, MayStudios, Google"
        },
        {
          "@type": "BreadcrumbList",
          "itemListElement": [{
            "@type": "ListItem",
            "position": 1,
            "name": "Portfolio Sven Maibaum",
            "item": "https://www.svenmaibaum.dev/index.html"
          },{
            "@type": "ListItem",
            "position": 2,
            "name": "Projekte",
            "item": "https://www.svenmaibaum.dev/index.html#projects"
          },{
            "@type": "ListItem",
            "position": 3,
            "name": "Gemma-2b-it-Toxic-v2.0"
          }]
        }
      ]
    }
    </script>
</head>

<body class="antialiased">

    <header class="sticky top-0 z-40 glassmorphism shadow-md">
        <div class="container mx-auto px-6 py-4 flex justify-between items-center">
            <a href="../index.html#home" class="text-xl font-bold gradient-text">Sven Maibaum</a>
            <div class="flex items-center">
                <a href="../index.html#projects" class="hover:text-teal-400 transition duration-300">
                    <i class="fas fa-arrow-left mr-2"></i>Zurück zu Projekten
                </a>
                <button id="theme-toggle" type="button" class="theme-switcher" title="Toggle theme">
                    <svg id="theme-toggle-dark-icon" class="hidden w-5 h-5" fill="currentColor" viewBox="0 0 20 20"
                        xmlns="http://www.w3.org/2000/svg">
                        <path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path>
                    </svg>
                    <svg id="theme-toggle-light-icon" class="hidden w-5 h-5" fill="currentColor" viewBox="0 0 20 20"
                        xmlns="http://www.w3.org/2000/svg">
                        <path
                            d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z"
                            fill-rule="evenodd" clip-rule="evenodd"></path>
                    </svg>
                </button>
            </div>
        </div>
    </header>

    <main class="project-detail-container section-padding fade-in-up visible">
        <div class="project-detail-header">
            <h1 class="gradient-text">Gemma-2b-it-Toxic-v2.0</h1>
            <p class="project-subtitle">Fine-tuned Language Model für Forschungszwecke zu unzensierten und toxischen
                Daten. Entwickelt von Google und MayStudios.</p>
        </div>

        <img src="https://placehold.co/900x500/2c7a7b/FFFFFF?text=Gemma+Toxic+LLM+Visualisierung"
            alt="Gemma-2b-it-Toxic-v2.0 Sprachmodell Visualisierung" class="project-image-full" loading="lazy">
        <div class="project-detail-content">
            <h2 class="gradient-text">Modelldetails</h2>
            <p>
                Dieses Modell, benannt "Gemma-2b-it-Toxic-v2.0", ist eine feinabgestimmte Version eines größeren
                Sprachmodells, das speziell darauf zugeschnitten ist, Text basierend auf unzensierten und toxischen
                Daten zu verstehen und zu generieren. Es wurde entwickelt, um die Fähigkeiten und Grenzen von
                Sprachmodellen zu erforschen, wenn sie einem breiteren Spektrum menschlicher Äußerungen ausgesetzt sind,
                einschließlich solcher, die allgemein als unangemessen oder schädlich gelten.
            </p>
            <p><strong>Entwickler/Institution:</strong> Google, MayStudios (Sven Maibaum)</p>

            <h3>Verwendungszweck</h3>
            <p><strong>Primärer Nutzen:</strong> Dieses Modell ist ausschließlich für Forschungszwecke gedacht, mit dem
                Ziel, die Auswirkungen und Herausforderungen des Trainings von KI-Systemen auf unzensierte Daten zu
                untersuchen. Dazu gehören die Verbreitung schädlicher Verzerrungen, die Generierung illegaler oder
                unethischer Inhalte und die technischen Herausforderungen bei der Filterung und Kontrolle solcher
                Ausgaben.</p>
            <p><strong>Sekundärer Nutzen:</strong> Das Modell kann auch zu Bildungszwecken dienen, um die Bedeutung
                ethischer KI-Entwicklung und die potenziellen Folgen der Vernachlässigung von Inhaltsmoderation in
                Trainingsdaten hervorzuheben.</p>
            <p><strong>Außerhalb des Geltungsbereichs:</strong> Die Verwendung dieses Modells zur Generierung von
                Inhalten für den öffentlichen Verbrauch oder in Anwendungen außerhalb kontrollierter, ethischer
                Forschungsumgebungen wird dringend abgeraten und gilt als nicht bestimmungsgemäß.</p>

            <h3>Trainingsdaten</h3>
            <p>
                Das "Gemma-2b-it-Toxic-v2.0"-Modell wurde auf einem Datensatz feinabgestimmt, der aus unzensierten und
                toxischen Inhalten besteht. Diese stammen von verschiedenen Online-Foren und Plattformen, die für
                weniger moderierte Interaktionen bekannt sind. Der Datensatz umfasst ein breites Spektrum an Sprache,
                von schädlichen und missbräuchlichen bis hin zu kontroversen und politisch aufgeladenen Inhalten.
                Des Weiteren wurden einige Inhalte von der Version 1 von "Svenni551/gemma-2b-it-toxic-dpo-v0.2"
                generiert.
            </p>

            <h3>Ethische Überlegungen</h3>
            <p><strong>Risiken und Schäden:</strong> Das Modell hat das Potenzial, Texte zu generieren, die schädlich,
                beleidigend oder illegal sind. Nutzer werden dringend gebeten, die Auswirkungen der Verwendung oder
                Verbreitung solcher Inhalte zu berücksichtigen, einschließlich der Verfestigung von Vorurteilen, der
                Förderung von Hassreden und der rechtlichen Folgen der Verbreitung verbotenen Materials.</p>
            <p><strong>Maßnahmen zur Risikominderung:</strong> Es wurden Anstrengungen unternommen, um potenzielle
                Schäden zu mindern, darunter die Beschränkung des Zugangs zum Modell auf Forscher und Entwickler mit
                einem klaren und ethischen Anwendungsfall sowie die Implementierung von Schutzmaßnahmen in Anwendungen,
                die dieses Modell verwenden, um als schädlich oder unangemessen erachtete generierte Inhalte zu filtern
                oder zu kennzeichnen.</p>
            <p><strong>Einschränkungen:</strong> Das Verständnis und die Generierung von Inhalten durch das Modell sind
                inhärent von seinen Trainingsdaten beeinflusst. Daher kann es Verzerrungen, Ungenauigkeiten oder eine
                Neigung zur Generierung unerwünschter Inhalte aufweisen.</p>
            <p><strong>Empfehlungen:</strong> Nutzern dieses Modells wird empfohlen, den Umfang und die ethischen
                Grenzen ihrer Forschungs- oder Bildungsprojekte klar zu definieren, robuste Mechanismen zur
                Inhaltsmoderation und -filterung bei der Analyse der Modellausgaben zu implementieren und
                Ethikkommissionen oder Aufsichtsgremien bei der Planung von Forschungsvorhaben mit diesem Modell
                einzubinden.</p>

            <h3>Eingesetzte Technologien & Konzepte</h3>
            <div class="my-4">
                <span class="tech-tag tech-tag-teal">AI/ML</span>
                <span class="tech-tag tech-tag-yellow">Python</span>
                <span class="tech-tag tech-tag-gray">Transformers</span>
                <span class="tech-tag tech-tag-blue">PyTorch</span>
                <span class="tech-tag tech-tag-purple">Hugging Face</span>
                <span class="tech-tag tech-tag-orange">Language Model</span>
                <span class="tech-tag tech-tag-green">Fine-Tuning</span>
                <span class="tech-tag tech-tag-red">DPO</span>
                <span class="tech-tag tech-tag-gray">Ethical AI Research</span>
            </div>

            <h3>Nutzungshinweise & Code-Beispiele</h3>
            <p>Die Nutzung des Modells erfordert die Installation von `transformers` und ggf. `accelerate` sowie
                `bitsandbytes` für Quantisierung. Die Code-Snippets auf der Hugging Face Seite zeigen die
                Implementierung für CPU, GPU, verschiedene Präzisionen und quantisierte Versionen.</p>
            <p>Ein spezifisches Chat-Template muss für konversationelle Nutzung eingehalten werden: `&lt;bos&gt;
                &lt;start_of_turn&gt;user\n{user_message}&lt;end_of_turn&gt;\n&lt;start_of_turn&gt;model\n`.</p>

            <div class="mt-8">
                <a href="https://huggingface.co/Svenni551/gemma-2b-it-toxic-v2.0" target="_blank"
                    rel="noopener noreferrer"
                    class="bg-gradient-to-r text-white font-medium py-3 px-6 rounded-lg transition duration-300 transform hover:scale-105 inline-block shadow-md button-like-class">
                    Zum Modell auf Hugging Face <i class="fas fa-external-link-alt ml-2"></i>
                </a>
            </div>
        </div>

        <a href="../index.html#projects" class="back-to-portfolio">
            <i class="fas fa-arrow-left mr-2"></i>Alle Projekte anzeigen
        </a>
    </main>

    <footer class="py-8 mt-12">
        <div class="container mx-auto px-6 text-center">
            <p>&copy; <span id="currentYearDetailGemma"></span> Sven Maibaum. Alle Rechte vorbehalten.</p>
        </div>
    </footer>
    <script>
        const currentYearDetailElementGemma = document.getElementById('currentYearDetailGemma');
        if (currentYearDetailElementGemma) {
            currentYearDetailElementGemma.textContent = new Date().getFullYear();
        }
    </script>
    <script src="../js/theme.js" defer></script>
</body>

</html>